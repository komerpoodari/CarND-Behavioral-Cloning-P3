{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = \"./180204-00/\" #\"./180203-00/\"\n",
    "model_name = \"180209-00.h5\"\n",
    "IMG_SHAPE = (160, 320, 3)\n",
    "lines = [] \n",
    "images = []\n",
    "measurements = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_training_data(directory):\n",
    "    csv_fname = directory + \"driving_log.csv\"\n",
    "    print(csv_fname)\n",
    "    f_csv = open (csv_fname)\n",
    "    print(f_csv)\n",
    "    read_buffer = csv.reader(f_csv)\n",
    "    for a_line in read_buffer:\n",
    "        lines.append(a_line)\n",
    "\n",
    "    #modify source path to relative path\n",
    "    for a_line in lines:\n",
    "        orig_source_path = a_line [0]  #center image\n",
    "\n",
    "        #exclude any header lines\n",
    "        if (a_line[0] == \"center\"):\n",
    "            print(a_line)\n",
    "            continue\n",
    "\n",
    "        f_name = orig_source_path.split('\\\\')[-1]  # just the file name portion for windows based files\n",
    "        current_image_path = directory +\"IMG/\" + f_name\n",
    "        #print(current_image_path)\n",
    "        an_img  = cv2.imread(current_image_path, cv2.IMREAD_COLOR)\n",
    "        if (an_img == None):\n",
    "            print(\"None file: \",current_image_path)\n",
    "            continue\n",
    "            \n",
    "        #add the image & steering to the training set    \n",
    "        images.append(an_img)\n",
    "        measurements.append (float(a_line[3]))\n",
    "        \n",
    "        #add the flip side of the image\n",
    "        #image_flipped = np.fliplr(image)\n",
    "        #measurement_flipped = -measurement\n",
    "        images.append(np.fliplr(an_img))\n",
    "        measurements.append (-float(a_line[3]))\n",
    "        \n",
    "        #close the opened file\n",
    "        f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./180204-00/driving_log.csv\n",
      "<_io.TextIOWrapper name='./180204-00/driving_log.csv' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py:23: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (27128, 160, 320, 3), y_train.shape\n"
     ]
    }
   ],
   "source": [
    "add_training_data(current_dir)\n",
    "#add_training_data(\"./180203-00/\")\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "    \n",
    "print(\"X_train shape {}, y_train.shape\".format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[185 145 116]\n",
      "  [185 145 116]\n",
      "  [184 144 115]\n",
      "  ..., \n",
      "  [ 53  66  64]\n",
      "  [ 54  61  58]\n",
      "  [ 70  75  73]]\n",
      "\n",
      " [[185 145 116]\n",
      "  [185 145 116]\n",
      "  [185 145 116]\n",
      "  ..., \n",
      "  [ 20  43  39]\n",
      "  [  9  31  26]\n",
      "  [ 39  61  56]]\n",
      "\n",
      " [[186 146 117]\n",
      "  [186 146 117]\n",
      "  [186 146 117]\n",
      "  ..., \n",
      "  [ 20  54  48]\n",
      "  [ 15  53  47]\n",
      "  [ 17  58  51]]\n",
      "\n",
      " ..., \n",
      " [[ 71  81  81]\n",
      "  [ 68  78  78]\n",
      "  [ 64  74  74]\n",
      "  ..., \n",
      "  [ 95 113 114]\n",
      "  [ 93 111 112]\n",
      "  [ 91 109 110]]\n",
      "\n",
      " [[ 45  55  55]\n",
      "  [ 51  61  61]\n",
      "  [ 58  68  68]\n",
      "  ..., \n",
      "  [ 98 116 117]\n",
      "  [ 94 112 113]\n",
      "  [ 90 108 109]]\n",
      "\n",
      " [[ 43  53  53]\n",
      "  [ 48  58  58]\n",
      "  [ 53  63  63]\n",
      "  ..., \n",
      "  [105 123 124]\n",
      "  [ 94 112 113]\n",
      "  [ 86 104 105]]]\n"
     ]
    }
   ],
   "source": [
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create and train the model.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Dense, Flatten, Lambda\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### TODO: Define your architecture.\n",
    "krnl_sz = 3                ## kernel size for convolutions - smaller better for better localization.\n",
    "pl_sz = 2                  ## pool size for max pooling\n",
    "classes= 30                ## output classes - nornalized  x, y positions of each feature point x 15\n",
    "\n",
    "\n",
    "#start with input layer with normalization of mean = 0 and range [-0.5: 0.5]\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape= IMG_SHAPE))\n",
    "\n",
    "\n",
    "#Take NVIDIA paper suggested architecture as per \n",
    "# https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "## FIRST LAYER SET\n",
    "##  Define the first 2D convolutional layer with proper input shape and 32 filters to start with, relu activation.\n",
    "model.add(Conv2D(filters=32, kernel_size= krnl_sz, padding='same', activation='relu', \n",
    "                        input_shape=(96, 96, 1)))\n",
    "## Add pooling layer\n",
    "model.add(MaxPooling2D(pool_size= pl_sz))\n",
    "\n",
    "## Add minimal drop out in early stage.\n",
    "model.add(Dropout(0.10))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "\n",
    "#### SECOND LAYER SET\n",
    "## Define the second 2D with increased number of filters and relu activation.\n",
    "model.add(Conv2D(filters=64, kernel_size=krnl_sz, padding='same', activation='relu'))\n",
    "\n",
    "## Add pooling layer\n",
    "model.add(MaxPooling2D(pool_size=pl_sz))\n",
    "\n",
    "## Add moderate drop out to reduce overfitting.\n",
    "model.add(Dropout(0.20))\n",
    "          \n",
    "####  THIRD LAYER SET\n",
    "## Define the third 2D with increased number of filters and relu activation.\n",
    "model.add(Conv2D(filters=128, kernel_size=krnl_sz, padding='same', activation='relu'))\n",
    "\n",
    "## Add pooling layer\n",
    "model.add(MaxPooling2D(pool_size=pl_sz))\n",
    "\n",
    "## Add typical drop out to reduce overfitting.\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Flatten => RELU layers\n",
    "model.add(Flatten())\n",
    "\n",
    "###  Add Fully connected dense layer with 500 nodes\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "## Add strong drop out rate at this later stage.\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "### ensure default linear output without 'relu' or 'softmax'\n",
    "model.add(Dense(classes)) #no softmax i.e. no non-linearity\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21702 samples, validate on 5426 samples\n",
      "Epoch 1/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.0588Epoch 00000: val_loss improved from inf to 2.86945, saving model to weights.best.adam.hdf5\n",
      "21702/21702 [==============================] - 33s - loss: 4.0585 - val_loss: 2.8695\n",
      "Epoch 2/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 3.8066Epoch 00001: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 3.8062 - val_loss: 11.0960\n",
      "Epoch 3/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.4825Epoch 00002: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 4.4819 - val_loss: 3.2594\n",
      "Epoch 4/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 3.8992Epoch 00003: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 3.9012 - val_loss: 5.9598\n",
      "Epoch 5/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.0648Epoch 00004: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 4.0643 - val_loss: 3.8367\n",
      "Epoch 6/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.3179Epoch 00005: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 4.3179 - val_loss: 6.1710\n",
      "Epoch 7/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.1804Epoch 00006: val_loss improved from 2.86945 to 2.86450, saving model to weights.best.adam.hdf5\n",
      "21702/21702 [==============================] - 27s - loss: 4.1800 - val_loss: 2.8645\n",
      "Epoch 8/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.6168Epoch 00007: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 4.6162 - val_loss: 3.3122\n",
      "Epoch 9/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 3.8568Epoch 00008: val_loss did not improve\n",
      "21702/21702 [==============================] - 27s - loss: 3.8567 - val_loss: 5.9879\n",
      "Epoch 10/10\n",
      "21696/21702 [============================>.] - ETA: 0s - loss: 4.2175Epoch 00009: val_loss did not improve\n",
      "21702/21702 [==============================] - 28s - loss: 4.2167 - val_loss: 6.1212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape= IMG_SHAPE))\n",
    "model.add(Flatten ())\n",
    "model.add(Dense(1))\n",
    "\n",
    "## TODO: Compile the model\n",
    "model.compile(loss ='mse',optimizer='adam')\n",
    "# TODO: Compile the model using a loss function and an optimizer.\n",
    "#model.compile(loss = 'mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "## TODO: Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.adam.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "hist = model.fit(X_train, y_train, nb_epoch = N_EPOCHS, shuffle = True, callbacks=[checkpointer], verbose=1, validation_split=0.2)\n",
    "\n",
    "#model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch = N_EPOCHS)\n",
    "\n",
    "#save model\n",
    "model.save (model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
