{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = \"./180204-00/\" #\"./180203-00/\"\n",
    "model_name = \"180209-00.h5\"\n",
    "IMG_SHAPE = (160, 320, 3)\n",
    "lines = [] \n",
    "images = []\n",
    "measurements = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_training_data(directory):\n",
    "    csv_fname = directory + \"driving_log.csv\"\n",
    "    print(csv_fname)\n",
    "    f_csv = open (csv_fname)\n",
    "    print(f_csv)\n",
    "    read_buffer = csv.reader(f_csv)\n",
    "    for a_line in read_buffer:\n",
    "        lines.append(a_line)\n",
    "\n",
    "    #modify source path to relative path\n",
    "    for a_line in lines:\n",
    "        orig_source_path = a_line [0]  #center image\n",
    "\n",
    "        #exclude any header lines\n",
    "        if (a_line[0] == \"center\"):\n",
    "            print(a_line)\n",
    "            continue\n",
    "\n",
    "        f_name = orig_source_path.split('\\\\')[-1]  # just the file name portion for windows based files\n",
    "        current_image_path = directory +\"IMG/\" + f_name\n",
    "        #print(current_image_path)\n",
    "        an_img  = cv2.imread(current_image_path, cv2.COLOR_BGR2RGB)\n",
    "        if (an_img.all() == None):\n",
    "            print(\"None file: \",current_image_path)\n",
    "            continue\n",
    "            \n",
    "        #add the image & steering to the training set    \n",
    "        images.append(an_img)\n",
    "        measurements.append (float(a_line[3]))\n",
    "        \n",
    "        #add the flip side of the image\n",
    "        #image_flipped = np.fliplr(image)\n",
    "        #measurement_flipped = -measurement\n",
    "        images.append(np.fliplr(an_img))\n",
    "        measurements.append (-float(a_line[3]))\n",
    "        \n",
    "        #close the opened file\n",
    "        f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_training_data(current_dir)\n",
    "#add_training_data(\"./180203-00/\")\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "    \n",
    "print(\"X_train shape {}, y_train.shape\".format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the model.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_4 (Lambda)                (None, 160, 320, 3)   0           lambda_input_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 156, 316, 24)  1824        lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 78, 158, 24)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 78, 158, 24)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 74, 154, 48)   28848       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 37, 77, 48)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 37, 77, 48)    0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 33, 73, 64)    76864       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 16, 36, 64)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 16, 36, 64)    0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 36864)         0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            2359360     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 64)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 32)            2080        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 32)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 16)            528         dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 16)            0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             17          dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2,469,521\n",
      "Trainable params: 2,469,521\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Define your architecture here.\n",
    "### TODO: Define your architecture.\n",
    "n_filters1 = 24\n",
    "krnl_sz1 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding1 = 'valid'\n",
    "activation1 = 'relu'\n",
    "dropout1 = 0.1\n",
    "pool_sz1 = 2\n",
    "\n",
    "n_filters2 = 36\n",
    "krnl_sz2 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding2 = 'valid'\n",
    "activation2 = 'relu'\n",
    "dropout2 = 0.1\n",
    "\n",
    "n_filters2 = 48\n",
    "krnl_sz2 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding2 = 'valid'\n",
    "activation2 = 'relu'\n",
    "dropout2 = 0.1\n",
    "pool_sz2 = 2\n",
    "\n",
    "n_filters3 = 64\n",
    "krnl_sz3 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding3 = 'valid'\n",
    "activation3 = 'relu'\n",
    "dropout3 = 0.1\n",
    "pool_sz3 = 2\n",
    "\n",
    "n_nodes4 = 64\n",
    "activation4 = 'relu'\n",
    "dropout4 = 0.1\n",
    "\n",
    "n_nodes5 = 32\n",
    "activation5 = 'relu'\n",
    "dropout5 = 0.1\n",
    "\n",
    "n_nodes6 = 16\n",
    "activation6 = 'relu'\n",
    "dropout6 = 0.1\n",
    "\n",
    "n_classes= 1             ## output classes - nornalized  x, y positions of each feature point x 15\n",
    "\n",
    "\n",
    "#start with input layer with normalization of mean = 0 and range [-0.5: 0.5]\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape= IMG_SHAPE))\n",
    "\n",
    "\n",
    "#Take NVIDIA paper suggested architecture as per \n",
    "# https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "## Layer 1\n",
    "##  Define the first 2D convolutional layer with proper input shape and 32 filters to start with, relu activation.\n",
    "model.add(Convolution2D(n_filters1,krnl_sz1 ,krnl_sz1, border_mode=padding1, activation = activation1))\n",
    "model.add(MaxPooling2D(pool_size= (pool_sz1, pool_sz1))) ## Add pooling layer\n",
    "model.add(Dropout(dropout1))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "\n",
    "## Layer 2\n",
    "model.add(Convolution2D(n_filters2,krnl_sz2 ,krnl_sz2, border_mode=padding2, activation = activation2))\n",
    "model.add(MaxPooling2D(pool_size= (pool_sz2, pool_sz2)))\n",
    "model.add(Dropout(dropout2))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "## Layer 3\n",
    "model.add(Convolution2D(n_filters3,krnl_sz3 ,krnl_sz3, border_mode=padding3, activation = activation3))\n",
    "model.add(MaxPooling2D(pool_size= (pool_sz3, pool_sz3)))\n",
    "model.add(Dropout(dropout3))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "\n",
    "# Flatten => RELU layers\n",
    "model.add(Flatten())\n",
    "\n",
    "### Layer 4\n",
    "model.add(Dense(n_nodes4, activation= activation4))\n",
    "model.add(Dropout(dropout4)) ## Add strong drop out rate at this later stage.\n",
    "\n",
    "### Layer 5\n",
    "model.add(Dense(n_nodes5, activation= activation5))\n",
    "model.add(Dropout(dropout5)) ## Add strong drop out rate at this later stage.\n",
    "\n",
    "### Layer 6\n",
    "model.add(Dense(n_nodes6, activation= activation6))\n",
    "model.add(Dropout(dropout6)) ## Add strong drop out rate at this later stage.\n",
    "\n",
    "### Layer 7\n",
    "model.add(Dense(n_classes))\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Compile the model\n",
    "model.compile(loss ='mse',optimizer='adam')\n",
    "# TODO: Compile the model using a loss function and an optimizer.\n",
    "#model.compile(loss = 'mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "## TODO: Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.adam.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "hist = model.fit(X_train, y_train, nb_epoch = N_EPOCHS, shuffle = True, callbacks=[checkpointer], verbose=1, validation_split=0.2)\n",
    "\n",
    "#model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch = N_EPOCHS)\n",
    "\n",
    "#save model\n",
    "model.save (model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
