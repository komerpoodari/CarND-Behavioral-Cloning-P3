{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = \"./180204-00/\" #\"./180203-00/\"\n",
    "model_name = \"180209-00.h5\"\n",
    "IMG_SHAPE = (160, 320, 3)\n",
    "lines = [] \n",
    "images = []\n",
    "measurements = []\n",
    "side_camera_angle_correction = 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_an_image (path, an_angle, img_list, angle_list):\n",
    "    #print(path)\n",
    "    an_img  = cv2.imread(path, cv2.COLOR_BGR2RGB)\n",
    "    if (an_img.all() == None):\n",
    "        print(\"None file: \", path)\n",
    "        return\n",
    "            \n",
    "    #add the image & steering to the training set    \n",
    "    img_list.append(an_img)\n",
    "    angle_list.append (an_angle)\n",
    "        \n",
    "    #add the flip side of the image\n",
    "    #image_flipped = np.fliplr(image)\n",
    "    #measurement_flipped = -measurement\n",
    "    img_list.append(np.fliplr(an_img))\n",
    "    angle_list.append (-(an_angle))\n",
    "\n",
    "def add_images_of_row (a_line, img_list, angle_list, directory):\n",
    "    #exclude any header lines\n",
    "    if (a_line[0] == \"center\"):\n",
    "        print(a_line)\n",
    "        return\n",
    "\n",
    "    #process center image\n",
    "    orig_source_path = a_line[0]\n",
    "    f_name = orig_source_path.split('\\\\')[-1]  # just the file name portion for windows based files\n",
    "    current_image_path = directory +\"IMG/\" + f_name\n",
    "    angle = float(a_line[3])\n",
    "    process_an_image (current_image_path, angle, img_list, angle_list)\n",
    "\n",
    "    \n",
    "    #process left image\n",
    "    orig_source_path = a_line[1]\n",
    "    f_name = orig_source_path.split('\\\\')[-1]  # just the file name portion for windows based files\n",
    "    current_image_path = directory +\"IMG/\" + f_name\n",
    "    angle = angle + side_camera_angle_correction\n",
    "    process_an_image (current_image_path, angle, img_list, angle_list)\n",
    "\n",
    "    #process right image\n",
    "    orig_source_path = a_line[2]\n",
    "    f_name = orig_source_path.split('\\\\')[-1]  # just the file name portion for windows based files\n",
    "    current_image_path = directory +\"IMG/\" + f_name\n",
    "    angle = angle - side_camera_angle_correction\n",
    "    process_an_image (current_image_path, angle, img_list, angle_list)\n",
    "   \n",
    "\n",
    "def add_training_data(directory):\n",
    "    csv_fname = directory + \"driving_log.csv\"\n",
    "    print(csv_fname)\n",
    "    f_csv = open (csv_fname)\n",
    "    print(f_csv)\n",
    "    read_buffer = csv.reader(f_csv)\n",
    "    for a_line in read_buffer:\n",
    "        add_images_of_row (a_line, images, measurements, directory)\n",
    "        \n",
    "    #close the opened file\n",
    "    f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./180204-00/driving_log.csv\n",
      "<_io.TextIOWrapper name='./180204-00/driving_log.csv' mode='r' encoding='cp1252'>\n",
      "X_train shape (81391, 160, 320, 3), y_train.shape\n"
     ]
    }
   ],
   "source": [
    "add_training_data(current_dir)\n",
    "#add_training_data(\"./180203-00/\")\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "    \n",
    "print(\"X_train shape {}, y_train.shape\".format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the model.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### TODO: Define your architecture.\n",
    "n_filters1 = 24\n",
    "krnl_sz1 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding1 = 'valid'\n",
    "activation1 = 'relu'\n",
    "dropout1 = 0.1\n",
    "pool_sz1 = 2\n",
    "\n",
    "n_filters2 = 36\n",
    "krnl_sz2 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding2 = 'valid'\n",
    "activation2 = 'relu'\n",
    "dropout2 = 0.1\n",
    "\n",
    "n_filters2 = 48\n",
    "krnl_sz2 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding2 = 'valid'\n",
    "activation2 = 'relu'\n",
    "dropout2 = 0.1\n",
    "pool_sz2 = 2\n",
    "\n",
    "n_filters3 = 64\n",
    "krnl_sz3 = 5                ## kernel size for convolutions - smaller better for better localization.\n",
    "padding3 = 'valid'\n",
    "activation3 = 'relu'\n",
    "dropout3 = 0.1\n",
    "pool_sz3 = 2\n",
    "\n",
    "n_nodes4 = 64\n",
    "activation4 = 'relu'\n",
    "dropout4 = 0.1\n",
    "\n",
    "n_nodes5 = 32\n",
    "activation5 = 'relu'\n",
    "dropout5 = 0.1\n",
    "\n",
    "n_nodes6 = 16\n",
    "activation6 = 'relu'\n",
    "dropout6 = 0.1\n",
    "\n",
    "n_classes= 1             ## output classes - nornalized  x, y positions of each feature point x 15\n",
    "\n",
    "\n",
    "#start with input layer with normalization of mean = 0 and range [-0.5: 0.5]\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape= IMG_SHAPE))\n",
    "\n",
    "\n",
    "#Take NVIDIA paper suggested architecture as per \n",
    "# https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "## Layer 1\n",
    "##  Define the first 2D convolutional layer with proper input shape and 32 filters to start with, relu activation.\n",
    "model.add(Convolution2D(n_filters1,krnl_sz1 ,krnl_sz1, border_mode=padding1, activation = activation1))\n",
    "model.add(MaxPooling2D(pool_size= (pool_sz1, pool_sz1))) ## Add pooling layer\n",
    "model.add(Dropout(dropout1))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "\n",
    "## Layer 2\n",
    "model.add(Convolution2D(n_filters2,krnl_sz2 ,krnl_sz2, border_mode=padding2, activation = activation2))\n",
    "model.add(MaxPooling2D(pool_size= (pool_sz2, pool_sz2)))\n",
    "model.add(Dropout(dropout2))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "## Layer 3\n",
    "model.add(Convolution2D(n_filters3,krnl_sz3 ,krnl_sz3, border_mode=padding3, activation = activation3))\n",
    "model.add(MaxPooling2D(pool_size= (pool_sz3, pool_sz3)))\n",
    "model.add(Dropout(dropout3))    ## dropout reduces the risk of overfitting.\n",
    "\n",
    "\n",
    "# Flatten => RELU layers\n",
    "model.add(Flatten())\n",
    "\n",
    "### Layer 4\n",
    "model.add(Dense(n_nodes4, activation= activation4))\n",
    "model.add(Dropout(dropout4)) ## Add strong drop out rate at this later stage.\n",
    "\n",
    "### Layer 5\n",
    "model.add(Dense(n_nodes5, activation= activation5))\n",
    "model.add(Dropout(dropout5)) ## Add strong drop out rate at this later stage.\n",
    "\n",
    "### Layer 6\n",
    "model.add(Dense(n_nodes6, activation= activation6))\n",
    "model.add(Dropout(dropout6)) ## Add strong drop out rate at this later stage.\n",
    "\n",
    "### Layer 7\n",
    "model.add(Dense(n_classes))\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Compile the model\n",
    "model.compile(loss ='mse',optimizer='adam')\n",
    "# TODO: Compile the model using a loss function and an optimizer.\n",
    "#model.compile(loss = 'mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "## TODO: Train the model\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.adam.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "hist = model.fit(X_train, y_train, nb_epoch = N_EPOCHS, shuffle = True, callbacks=[checkpointer], verbose=1, validation_split=0.2)\n",
    "\n",
    "#model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch = N_EPOCHS)\n",
    "\n",
    "#save model\n",
    "model.save (model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
